{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ca9da2-4594-4d74-8506-c6552bc74fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77c3f65-5903-41fc-9259-60c543ea6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f215b23-0517-4223-959a-d4c20157bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7673282f-bd8c-4102-bf64-2cd262a4ca71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b11d33-8a0e-4c8d-90a4-5eeb9c8fa0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac69e14f-7c9e-43e4-bb44-4126998bb5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 1.  Endpoint client\n",
    "# ---------------------------------------------------------------------\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"BASE10_API_KEY\", \"YOUR_API_KEY\"),\n",
    "    base_url=\"https://model-7qr7px53.api.baseten.co/environments/production/sync/v1\",\n",
    ")\n",
    "\n",
    "# Wrap client so responses are automatically parsed\n",
    "client = instructor.from_openai(client, mode=instructor.Mode.MD_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecf8cd-f118-48de-8c77-84dc7bf72731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f0fef-b30c-49d0-bf4c-beee7eb34822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 2.  Design an appropriate system prompt for these tasks\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d820ae4-f52a-4c04-9eef-495084fa118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Improve the system prompt for better performance on legal documents\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert legal transcript analyzer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511f8e0-feff-45b5-bbd4-d552c542d651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54805265-157b-4fd4-a5a5-36a0b3e57702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 3.  Load the transcript\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91862402-05a0-4a5f-9d3a-0826352531f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_TRANSCRIPT = open('transcript.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4768844-1dcc-4c95-8e1a-e15cfc298978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6e42b-2622-4d46-b6ea-e17527683c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0a58b1b-76ea-494e-8fed-325eefadb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 3.  Summarize the transcript (example)\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e295b244-065d-4f1e-8225-01d2726cc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE=\"\"\"\n",
    "Summarize this transcript\n",
    "{raw_transcript}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ee560-4d63-4dec-9fe2-ea121e4f88a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d694c371-9187-4706-8667-0d2a3625401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptSummary(BaseModel):\n",
    "    summary: str = Field(..., description=\"Transcript summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f81a59-1abb-44b1-94f9-6224b5f42385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a20c9227-1d82-4d45-a429-d6ee22cfbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_response, raw_summary_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=TranscriptSummary,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3134e-847a-4389-9a98-79d1a3539a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c25b3298-2157-4472-bc71-7b8fe141600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transcript records a deposition led by Terry Seligman, representing plaintiff Moonlight Plaza Associates, examining Chris Jacob, a senior environmental project manager at Cancun Farms. Jacob confirms her role involves overseeing environmental remediation of spill sites through hired consultants, though she does not directly manage day-to-day activities. She reviews consultants' documents, discusses remediation scope, and ensures compliance with state regulations for closure. Jacob clarifies that leases are not considered in remediation planning. The deposition includes technical setup discussions, document reviews (marked as Cancun Farms 1 and 2), and ongoing interrogatory responses when the transcript ends abruptly.\n"
     ]
    }
   ],
   "source": [
    "print(summary_response.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb53048-7921-4c0d-9df4-6a749e55f49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4841b7a-3aca-4e95-913f-4cabadfe0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model also includes reasoning tokens. Do you agree with it's reasoning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccfcb060-e015-40fa-8f23-984478f1cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I need to summarize this transcript. Let me start by reading through it carefully.\n",
      "\n",
      "The transcript starts with Terry Seligman from the law firm Richmond and Levine, P.C., representing the plaintiff Moonlight Plaza Associates. He's addressing Ms. Jacob, who's the deponent from Cancun Farms. There's some initial setup about technical issues and instructions for the deposition. Then, after confirming she's not under any influence, they start discussing the documents. \n",
      "\n",
      "The first document is Cancun Farms 1. Ms. Jacob is a senior environmental project manager who oversees spill remediation. She explains that they hire consultants for daily tasks but she reviews their documents and discusses the scope. There's some back and forth about whether leases affect remediation scope, and she says no because she doesn't review leases. The main goal is closing spills per regulations. \n",
      "\n",
      "Then they move to Cancun Farms 2, but the transcript cuts off while discussing interrogatory number four. \n",
      "\n",
      "So the summary should capture the main points: Terry's role, Ms. Jacob's position, her responsibilities involving consultants and remediation, the documents reviewed, and the focus on compliance without considering leases. Also note the ongoing discussion about interrogatories when the transcript ends. Need to keep it concise, in a single JSON object with \"summary\" key.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_summary_completion.choices[0].message.reasoning_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b149a1b-b732-4e13-8620-b7f9bb2b6938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b850ce-6b2a-4f8b-9f5e-4805e5dcb6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f43e6-c5e6-40fb-bfba-ed82a19e9e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537e372-6512-4c84-ae03-3cbdb67d687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 4.  Classify the type of legal proceeding\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b38d8f-dd29-4809-88ce-cbbef839ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design a prompt to classify the type of legal proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e90852f6-8367-4523-b49f-292d58aae933",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE=\"\"\"\n",
    "________\n",
    "{raw_transcript}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b955c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add attributes to a Pydantic model for the classification response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa170f71-881b-420f-bc24-fa3a23782e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalProceeding(BaseModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a46297-b69e-4443-b08f-ca34a6931f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "proceeding_response, raw_proceeding_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=TranscriptSummary,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc85cab-5424-4735-bba0-8c07648443a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923842f5-611c-48a2-b7b3-164fd8960f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5.  Identify each speaker listed\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a837e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design a prompt to identify each speaker listed (Speaker A, Speaker B, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0aef6-c019-49f0-8515-181267657f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE=\"\"\"\n",
    "________\n",
    "{raw_transcript}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ee3a5-fecd-43b3-9c12-bbf7d9d8c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Speakers(BaseModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add attributes to a Pydantic model for the speaker response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91041f-de2c-449d-afba-e00552bc6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_response, raw_speakers_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=TranscriptSummary,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1d7f8-43b2-41f4-aca1-1cf4cead8403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f026f-211c-4e84-bf1c-df230b158e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5.  Identify sections of cross-talk\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123eae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design a prompt to identify sections of cross-talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a797aa-7c48-42c8-bb9a-2868c897c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE=\"\"\"\n",
    "________\n",
    "{raw_transcript}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d57926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design the Pydantic model for the cross-talk response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835fffd-c07b-49e6-b267-19f73a2f8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossTalkAnalysis(BaseModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b759dc-9bb8-479a-84e2-5bea821ad03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstalk_response, raw_crosstalk_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=TranscriptSummary,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a761632-5168-4790-b434-03c648ca947f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
