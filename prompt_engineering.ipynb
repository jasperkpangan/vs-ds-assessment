{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ca9da2-4594-4d74-8506-c6552bc74fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77c3f65-5903-41fc-9259-60c543ea6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f215b23-0517-4223-959a-d4c20157bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac69e14f-7c9e-43e4-bb44-4126998bb5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 1.  Endpoint client\n",
    "# ---------------------------------------------------------------------\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"BASE10_API_KEY\", \"YOUR_API_KEY\"),\n",
    "    base_url=\"https://model-7qr7px53.api.baseten.co/environments/production/sync/v1\",\n",
    ")\n",
    "\n",
    "# Wrap client so responses are automatically parsed\n",
    "client = instructor.from_openai(client, mode=instructor.Mode.MD_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74f0fef-b30c-49d0-bf4c-beee7eb34822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 2.  Design an appropriate system prompt for these tasks\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d820ae4-f52a-4c04-9eef-495084fa118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Improve the system prompt for better performance on legal documents\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert legal transcript analyzer\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54805265-157b-4fd4-a5a5-36a0b3e57702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 3.  Load the transcript\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91862402-05a0-4a5f-9d3a-0826352531f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_TRANSCRIPT = open('transcript.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a58b1b-76ea-494e-8fed-325eefadb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 3.  Summarize the transcript (example)\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e295b244-065d-4f1e-8225-01d2726cc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE=\"\"\"\n",
    "Summarize this transcript\n",
    "{raw_transcript}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d694c371-9187-4706-8667-0d2a3625401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptSummary(BaseModel):\n",
    "    summary: str = Field(..., description=\"Transcript summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a20c9227-1d82-4d45-a429-d6ee22cfbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_response, raw_summary_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=TranscriptSummary,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c25b3298-2157-4472-bc71-7b8fe141600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transcript documents a deposition led by Terry Seligman, representing plaintiff Moonlight Plaza Associates, examining Ms. Jacob, a senior environmental project manager at Cancun Farms. Ms. Jacob confirms her role involves overseeing environmental remediation and assessments through hired consultants, though she does not directly manage day-to-day activities. She reviews consultant-provided documents and discusses remedial scope but does not dictate report preparation. Adjustments to scope are based on collaborative discussions and site conditions. Ms. Jacob reports to Cancun’s Vice President of Environmental and does not review property leases, focusing instead on regulatory compliance to achieve closure on spill sites. Two exhibits (Cancun Farms 1 and 2) are referenced during the deposition.\n"
     ]
    }
   ],
   "source": [
    "print(summary_response.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3dbe5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert legal transcript analyst with a strong focus on legal precision and clarity. \n",
    "Your role is to carefully analyze depositions, ensuring all legal terminology, procedural details, and testimony nuances are correctly interpreted and clearly conveyed.\n",
    "Maintain a professional, detailed, and exact tone appropriate for legal professionals relying on your summaries.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c34aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_response, raw_summary_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=TranscriptSummary,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db53fd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transcript details a deposition led by Terry Seligman, counsel for plaintiff Moonlight Plaza Associates, examining Ms. Jacob, a senior environmental project manager at Cancun Farms. After confirming technical setup and procedural instructions, Seligman establishes Ms. Jacob's role in overseeing environmental remediation at Cancun Farms, clarifying her reliance on external consultants for day-to-day remediation tasks. Key topics include her review of consultant-generated documents, her involvement in scoping remediation efforts, and her reliance on site history and regulatory requirements (rather than leases) to determine appropriate remediation scope. Objections are noted during questions about direct control over consultants. The deposition concludes with the marking of Exhibits Cancun Farms 1 and 2 for record-keeping.\n"
     ]
    }
   ],
   "source": [
    "print(summary_response.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4841b7a-3aca-4e95-913f-4cabadfe0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model also includes reasoning tokens. Do you agree with it's reasoning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccfcb060-e015-40fa-8f23-984478f1cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's tackle this query. The user wants a summary of the provided transcript in a specific JSON format. First, I need to understand the content of the transcript.\n",
      "\n",
      "The transcript starts with Speaker A, Terry Seligman, introducing himself and explaining the deposition process to Ms. Jacob. He checks if she's under any influence and confirms she's the designated deponent. Then, he presents documents (Cancun Farms 1 and 2) and asks about her role as a senior environmental project manager. The discussion covers her responsibilities, interactions with consultants, and how Cancun Farms determines remediation scopes. There are objections from Speaker C, but the main points are about her role, document reviews, and company procedures.\n",
      "\n",
      "Now, the summary needs to capture all these elements concisely. The JSON schema requires a \"summary\" key. I should mention the parties involved, the purpose of the deposition, her role, document discussions, scope determination, objections, and the conclusion with the next document. I must ensure it's detailed enough for legal professionals but remains a summary. I'll check for any technical terms or procedures to include accurately. Avoid any markdown, just plain text in the JSON. Let me structure it step by step to cover each part without missing key details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_summary_completion.choices[0].message.reasoning_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eaf2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = open('sample.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92b850ce-6b2a-4f8b-9f5e-4805e5dcb6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Introduction(BaseModel):\n",
    "    deponent_name: str = Field(..., description=\"Full name of the deponent\")\n",
    "    role: Optional[str] = Field(None, description=\"Role or title of the deponent in the organization or case\")\n",
    "    attorneys_present: List[str] = Field(..., description=\"Names of attorneys present during the deposition\")\n",
    "    instructions_given: Optional[str] = Field(None, description=\"Instructions provided to the deponent at the beginning\")\n",
    "    initial_demeanor_notes: Optional[str] = Field(None, description=\"Observed demeanor of the deponent at the start\")\n",
    "\n",
    "class BackgroundAndRole(BaseModel):\n",
    "    job_title: str = Field(..., description=\"Job title of the deponent\")\n",
    "    employer: Optional[str] = Field(None, description=\"Current or past employer relevant to the deposition\")\n",
    "    job_duties: Optional[str] = Field(None, description=\"Description of the deponent's job responsibilities\")\n",
    "    case_relationship: Optional[str] = Field(None, description=\"How the deponent is related to the case\")\n",
    "\n",
    "class ScopeOfWork(BaseModel):\n",
    "    decision_making_authority: Optional[str] = Field(None, description=\"Extent of the deponent's decision-making authority\")\n",
    "    interactions_with_consultants: Optional[str] = Field(None, description=\"Nature of the deponent's interactions with consultants\")\n",
    "    documents_handled: Optional[str] = Field(None, description=\"Types of documents the deponent handled\")\n",
    "    limitations: Optional[str] = Field(None, description=\"Limitations on the deponent's role or responsibilities\")\n",
    "\n",
    "class LegalRelevance(BaseModel):\n",
    "    admissions: Optional[List[str]] = Field(None, description=\"Statements that may be admissions\")\n",
    "    contradictions: Optional[List[str]] = Field(None, description=\"Inconsistencies in the testimony\")\n",
    "    regulatory_references: Optional[List[str]] = Field(None, description=\"Mentions of regulations or legal standards\")\n",
    "    contract_references: Optional[List[str]] = Field(None, description=\"Mentions of contracts or contractual obligations\")\n",
    "\n",
    "class KeyTestimonyAreas(BaseModel):\n",
    "    background_and_role: BackgroundAndRole = Field(..., description=\"Deponent's background and role in the matter\")\n",
    "    scope_of_work: Optional[ScopeOfWork] = Field(None, description=\"Deponent's scope of work and responsibilities\")\n",
    "    legal_relevance: Optional[LegalRelevance] = Field(None, description=\"Legally significant parts of the testimony\")\n",
    "\n",
    "class CredibilityNotes(BaseModel):\n",
    "    clarity: Optional[str] = Field(None, description=\"Clarity and coherence of the deponent's answers\")\n",
    "    technical_issues: Optional[str] = Field(None, description=\"Any audio or technical disruptions\")\n",
    "    signs_of_evasion: Optional[str] = Field(None, description=\"Indicators that the deponent may be evasive\")\n",
    "    demeanor: Optional[str] = Field(None, description=\"Behavior or attitude impacting credibility\")\n",
    "\n",
    "class Objection(BaseModel):\n",
    "    description: str = Field(..., description=\"Description of the objection raised\")\n",
    "    objecting_party: Optional[str] = Field(None, description=\"Name of the attorney or party who raised the objection\")\n",
    "    impact_on_testimony: Optional[str] = Field(None, description=\"Effect the objection had on the witness or the record\")\n",
    "\n",
    "class Quote(BaseModel):\n",
    "    quote_text: str = Field(..., description=\"Exact quoted statement from the deponent\")\n",
    "    timestamp_reference: Optional[str] = Field(None, description=\"Time reference where the quote appears\")\n",
    "\n",
    "class DepositionSummary(BaseModel):\n",
    "    case_title: str = Field(..., description=\"Title of the legal case\")\n",
    "    date_of_deposition: Optional[str] = Field(None, description=\"Date when the deposition was taken\")\n",
    "    deponent: str = Field(..., description=\"Name of the deponent\")\n",
    "    deposed_by: Optional[str] = Field(None, description=\"Name of the examining attorney\")\n",
    "    timestamps: Optional[str] = Field(None, description=\"Timestamp log format or file reference\")\n",
    "\n",
    "    introduction: Introduction = Field(..., description=\"Introduction section of the deposition\")\n",
    "    key_testimony_areas: KeyTestimonyAreas = Field(..., description=\"Main areas of testimony relevant to the case\")\n",
    "    credibility_notes: Optional[CredibilityNotes] = Field(None, description=\"Credibility-related observations\")\n",
    "    objections_noted: Optional[List[Objection]] = Field(None, description=\"List of objections made during deposition\")\n",
    "    important_quotes: Optional[List[Quote]] = Field(None, description=\"Key quotes from the deponent\")\n",
    "    summary_of_key_points: List[str] = Field(..., description=\"Summary list of important points from the deposition\")\n",
    "\n",
    "USER_PROMPT_TEMPLATE = f\"\"\"\n",
    "You are an expert legal transcript analyst.  \n",
    "**Task:** Use the following deposition outline to generate a structured summary of the transcript.\n",
    "\n",
    "### Outline:\n",
    "{outline}\n",
    "\n",
    "### Transcript:\n",
    "{RAW_TRANSCRIPT}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcad11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_response, raw_summary_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=DepositionSummary,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d2b9033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moonlight Plaza Associates v. Cancun Farms'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.case_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "238f43e6-c5e6-40fb-bfba-ed82a19e9e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andrea Jacob'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.deponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e44751d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Terry Seligman (Richmond and Levine, P.C.)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.deposed_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53820796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Andrea Jacob', 'Senior Environmental Project Manager')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.introduction.deponent_name, summary_response.introduction.role\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3215a88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BackgroundAndRole(job_title='Senior Environmental Project Manager', employer='Cancun Farms', job_duties='Oversee assessment and remediation work on sites with open spills; interface with environmental consultants.', case_relationship='Designated corporate representative for deposition topics related to environmental remediation.')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.key_testimony_areas.background_and_role\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b08a5bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScopeOfWork(decision_making_authority='Reviews and discusses scope proposals from consultants but does not dictate specific remedial methods.', interactions_with_consultants='Collaborates with consultants on remediation plans; reviews and edits consultant-prepared documents.', documents_handled='Environmental reports and remediation plans (e.g., Exhibit Cancun Farms 1 and 2).', limitations='Does not review leases; defers to consultants for report preparation per regulatory standards.')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.key_testimony_areas.scope_of_work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4cf37f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LegalRelevance(admissions=['I do not normally review leases.', 'We just work with my consultant to close the spills.'], contradictions=None, regulatory_references=['State and local regulations for no further action letters.'], contract_references=['Environmental consultant agreements.'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.key_testimony_areas.legal_relevance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a875a5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CredibilityNotes(clarity='Answers generally clear but occasionally affected by technical delays.', technical_issues='Audio delay noted; deponent repeated questions for clarity.', signs_of_evasion='No overt evasion; direct answers provided.', demeanor='Professional and cooperative despite technical challenges.')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.credibility_notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1abfb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Objection(description='Objection to form (unclear specific ground); overruled.', objecting_party='Speaker C', impact_on_testimony='Deponent answered after repetition of the question.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.objections_noted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b96610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Quote(quote_text='I do not normally review leases.', timestamp_reference='00:06:45'),\n",
       " Quote(quote_text='I just work with my consultant to close the spills.', timestamp_reference='00:07:06')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.important_quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "496812dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andrea Jacob oversees environmental remediation projects for Cancun Farms but relies on third-party consultants for day-to-day execution.',\n",
       " 'She does not review leases or dictate specific remedial methods to consultants, instead focusing on scope discussions.',\n",
       " 'Admitted to excluding lease reviews from remediation decisions, citing reliance on consultants.',\n",
       " 'Remediation goals align with state and local regulatory standards for closure.',\n",
       " \"Designated corporate representative with direct oversight of environmental consultants' work products.\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_response.summary_of_key_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3a74e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let me tackle this query step by step. The user wants me to generate a structured JSON summary of a deposition transcript based on the provided outline. First, I need to parse the transcript and map the information to the schema they specified.\n",
      "\n",
      "Starting with the **Case Title**, the transcript mentions \"Cancun Farms\" and the plaintiff \"Moonlight Plaza Associates,\" so I'll combine that into the case title. The **Deponent** is clearly Ms. Jacob, and the **Date of Deposition** isn't explicitly stated, so I'll leave it as null. **Timestamps Covered** should be from the start to the end of the transcript, which is up to 00:08:46. The **Deposed By** is Terry Seligman from Richmond and Levine, P.C., representing the plaintiff.\n",
      "\n",
      "Moving to the **Introduction** section: The deponent's name is Andrea Jacob, and her role is Senior Environmental Project Manager. The attorneys present are Terry Seligman and possibly someone named Porter (from \"Mr. Porter\" when marking exhibits). The instructions given include verbal answers and technical issues mentioned. Initial demeanor notes mention a delay and technical issues, so I'll note that.\n",
      "\n",
      "For **Key Testimony Areas**, under Background and Role, Andrea's job title and employer are clear. Her duties involve overseeing assessments and remediation, but she doesn't directly manage; they hire consultants. The case relationship is her role as the designated deponent.\n",
      "\n",
      "Scope of Work includes her lack of direct decision-making authority, interactions with consultants, reviewing documents, and limitations like not reviewing leases. Legal Relevance would have admissions about not reviewing leases and closing spills per regulations. Contradictions aren't obvious here, but regulatory references are mentioned.\n",
      "\n",
      "**Credibility Notes** should include the technical issues affecting clarity, possible signs of evasion if she's hesitant, but the transcript shows she answers directly, just with technical problems. Demeanor notes would mention cooperation despite the delay.\n",
      "\n",
      "**Objections Noted** are from Speaker C (probably opposing counsel) on form, but the deponent answered anyway. Impact was minor delays.\n",
      "\n",
      "Important Quotes are the ones she made about leases and working with consultants, with timestamps. The Summary of Key Points needs bullet points like her role, reliance on consultants, not reviewing leases, and regulatory compliance.\n",
      "\n",
      "I need to ensure all required fields are present, like job_title, deponent_name, attorneys_present, etc. Also, defaulting null where data isn't present, like contradictions or regulatory references if they aren't mentioned. Checking the schema to make sure each object is correctly structured, especially nested ones like Introduction and KeyTestimonyAreas.\n",
      "\n",
      "Finally, validating that the JSON syntax is correct, with proper commas, quotes, and structure. Making sure timestamps are correctly noted and that all parts of the outline are covered without adding extra information not in the transcript.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_summary_completion.choices[0].message.reasoning_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b537e372-6512-4c84-ae03-3cbdb67d687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 4.  Classify the type of legal proceeding\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33b38d8f-dd29-4809-88ce-cbbef839ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design a prompt to classify the type of legal proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e90852f6-8367-4523-b49f-292d58aae933",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE = f\"\"\"\n",
    "You are an expert legal transcript analyst.  \n",
    "\n",
    "**Task:** Determine the type of legal proceeding.\n",
    "   Common types include:\n",
    "   - Deposition  \n",
    "   - Arbitration  \n",
    "   - Trial (Civil or Criminal)  \n",
    "   - Hearing (Administrative, Pretrial, Evidentiary, etc.)  \n",
    "   - Mediation  \n",
    "   - Sentencing  \n",
    "   - Motion Hearing  \n",
    "   - Voir Dire  \n",
    "   - Grand Jury Proceeding\n",
    "\n",
    "   \n",
    "### Transcript:\n",
    "{RAW_TRANSCRIPT}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b955c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add attributes to a Pydantic model for the classification response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa170f71-881b-420f-bc24-fa3a23782e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalProceeding(BaseModel):\n",
    "    type_of_legal_proceeding: str = Field(..., description=\"Type of Legal Proceeding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7a46297-b69e-4443-b08f-ca34a6931f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "proceeding_response, raw_proceeding_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=LegalProceeding,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcc85cab-5424-4735-bba0-8c07648443a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for experiment in range(0,5):\n",
    "    proceeding_response, raw_proceeding_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=LegalProceeding,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.2 # Decrease to make it more deterministic, legal classification\n",
    "    )\n",
    "\n",
    "    results.append(proceeding_response.type_of_legal_proceeding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd85be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    total = len(labels)\n",
    "    counts = Counter(labels)\n",
    "    ent = 0.0\n",
    "    \n",
    "    for count in counts.values():\n",
    "        p = count / total\n",
    "        ent -= p * math.log2(p)\n",
    "    \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40c22a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89206c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's tackle this. The user wants me to determine the type of legal proceeding based on the provided transcript.\n",
      "\n",
      "First, I'll read through the transcript to pick up clues. The speaker starts by introducing himself as Terry Seligman from a law firm, representing the plaintiff. He mentions \"deposition\" several times in his instructions to the witness. For example, he says, \"I just have a list of general instructions I give to all deponents,\" which is a strong indicator of a deposition. \n",
      "\n",
      "The witness, Ms. Jacob, is being questioned about her role at Cancun Farms, her responsibilities, and her interactions with environmental consultants. The attorney also refers to exhibits being marked as \"Cancun Farms 1\" and \"Cancun Farms 2,\" which is typical in depositions where documents are entered into evidence. \n",
      "\n",
      "There's an objection from another speaker (probably opposing counsel) at 00:04:05 and 00:05:04, which is common in depositions when attorneys object to questions but still allow the witness to answer. The mention of \"interrogatory\" and discussing documents related to the case further support that this is part of a deposition process, as interrogatories are written questions that are part of pre-trial discovery, often followed by depositions.\n",
      "\n",
      "The setting seems to be a virtual meeting (due to mentions of a \"newer platform\" and technical issues), which aligns with modern deposition practices, especially post-pandemic. There's no mention of a judge, jury, or courtroom setting, which rules out trials, hearings, or sentencing. Terms like \"motion hearing\" or \"mediation\" don't fit here because the primary activity is taking testimony under oath, which is the hallmark of a deposition.\n",
      "\n",
      "So putting it all together, the transcript is clearly a deposition. The key phrases like \"deponent,\" \"marked as Exhibit,\" and the procedural instructions all point to that conclusion. The other types of proceedings don't match the context provided here.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_proceeding_completion.choices[0].message.reasoning_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "923842f5-611c-48a2-b7b3-164fd8960f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5.  Identify each speaker listed\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50a837e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design a prompt to identify each speaker listed (Speaker A, Speaker B, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94d0aef6-c019-49f0-8515-181267657f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE = f\"\"\"\n",
    "You are an expert legal transcript analyst.  \n",
    "\n",
    "**Task:** Identify and label each speaker in the transcript (e.g., Speaker A, Speaker B, etc.) with their most likely role or name, based on the context. \n",
    "    Common roles include:\n",
    "    - Attorney (name if available)\n",
    "    - Witness\n",
    "    - Judge\n",
    "    - Court Reporter\n",
    "    - Clerk\n",
    "    - Expert\n",
    "    - Defendant\n",
    "    - Plaintiff\n",
    "    - Arbitrator\n",
    "   \n",
    "### Transcript:\n",
    "{RAW_TRANSCRIPT}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "185ee3a5-fecd-43b3-9c12-bbf7d9d8c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Speakers(BaseModel):\n",
    "    speakers: Dict[str, str] = Field(..., description=\"Mapping of speaker to their name or role\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "038b57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add attributes to a Pydantic model for the speaker response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e91041f-de2c-449d-afba-e00552bc6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_response, raw_speakers_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=Speakers,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ab1d7f8-43b2-41f4-aca1-1cf4cead8403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Speaker A': 'Attorney (Plaintiff, Terry Seligman, Richmond and Levine, P.C.)',\n",
       " 'Speaker B': 'Witness (Senior Environmental Project Manager, Cancun Farms)',\n",
       " 'Speaker C': 'Attorney (Defense, objecting counsel)'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers_response.speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "867f026f-211c-4e84-bf1c-df230b158e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5.  Identify sections of cross-talk\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "123eae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design a prompt to identify sections of cross-talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43a797aa-7c48-42c8-bb9a-2868c897c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_TEMPLATE = f\"\"\"\n",
    "You are an expert legal transcript analyst.  \n",
    "\n",
    "**Task:** Identify every instance of cross-talk in the transcript — where two or more speakers talk over each other, interrupt, or speak simultaneously.\n",
    "Be exhaustive and do not miss any overlapping speech.\n",
    "\n",
    "**Instructions:**\n",
    "- Provide **start and end timestamps** for each crosstalk event\n",
    "- List the names of all speakers involved\n",
    "- Provide the overlapping lines **exactly as spoken**\n",
    "- Include a brief note describing the nature of the interruption or overlap\n",
    "\n",
    "### Transcript:\n",
    "{RAW_TRANSCRIPT}\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61d57926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design the Pydantic model for the cross-talk response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6835fffd-c07b-49e6-b267-19f73a2f8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossTalkAnalysis(BaseModel):\n",
    "    start_time: str = Field(..., description=\"Start timestamp of the crosstalk\")\n",
    "    end_time: str = Field(..., description=\"End timestamp of the crosstalk\")\n",
    "    speakers: List[str] = Field(..., description=\"List of speaker names involved in the crosstalk\")\n",
    "    lines: Dict[str, str] = Field(..., description=\"Mapping of speaker name to their overlapping spoken line\")\n",
    "    notes: Optional[str] = Field(None, description=\"Brief note describing nature of crosstalk\")\n",
    "\n",
    "class CrossTalkEvent(BaseModel):\n",
    "    events: List[CrossTalkAnalysis] = Field(..., description=\"List of all crosstalk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46b759dc-9bb8-479a-84e2-5bea821ad03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstalk_response, raw_crosstalk_completion = client.chat.completions.create_with_completion(\n",
    "    model=\"qwen-3\",\n",
    "    response_model=CrossTalkEvent,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "    ],\n",
    "    temperature=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a761632-5168-4790-b434-03c648ca947f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crosstalk_response.events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e6493c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CrossTalkAnalysis(start_time='00:04:05', end_time='00:04:08', speakers=['Speaker A', 'Speaker C'], lines={'Speaker A': 'So do you revise documents provided to you by. By those environmental consultants?', 'Speaker C': 'Objection. You may answer.'}, notes='Speaker C objects while Speaker A is asking the question, creating overlapping speech.'),\n",
       " CrossTalkAnalysis(start_time='00:04:24', end_time='00:04:25', speakers=['Speaker A', 'Speaker B'], lines={'Speaker A': 'Do you discuss those documents with the.', 'Speaker B': 'And I will make edits.'}, notes='Simultaneous speaking; Speaker B begins responding before Speaker A completes the question.'),\n",
       " CrossTalkAnalysis(start_time='00:06:16', end_time='00:06:20', speakers=['Speaker B', 'Speaker C'], lines={'Speaker B': \"If they're available.\", 'Speaker C': 'The connection is a little rough here.'}, notes='Speaker C comments on technical issues while Speaker B is responding, resulting in overlapping speech.'),\n",
       " CrossTalkAnalysis(start_time='00:07:27', end_time='00:07:28', speakers=['Speaker B', 'Speaker A'], lines={'Speaker B': 'President.', 'Speaker A': \"I'm sorry. I'm sorry to cut you off.\"}, notes='Speaker A interrupts Speaker B mid-response.')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstalk_response.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1e9c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(self):\n",
    "    print(f\"Crosstalk detected from {self.start_time} to {self.end_time}\")\n",
    "    print(f\"Speakers involved: {', '.join(self.speakers)}\")\n",
    "    print(\"Overlapping lines:\")\n",
    "    for speaker in self.speakers:\n",
    "        line = self.lines.get(speaker, \"\")\n",
    "        print(f\"  {speaker}: \\\"{line}\\\"\")\n",
    "    print(f\"Note: {self.notes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95462544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosstalk 1\n",
      "Crosstalk detected from 00:04:05 to 00:04:08\n",
      "Speakers involved: Speaker A, Speaker C\n",
      "Overlapping lines:\n",
      "  Speaker A: \"So do you revise documents provided to you by. By those environmental consultants?\"\n",
      "  Speaker C: \"Objection. You may answer.\"\n",
      "Note: Speaker C objects while Speaker A is asking the question, creating overlapping speech.\n",
      "----\n",
      "Crosstalk 2\n",
      "Crosstalk detected from 00:04:24 to 00:04:25\n",
      "Speakers involved: Speaker A, Speaker B\n",
      "Overlapping lines:\n",
      "  Speaker A: \"Do you discuss those documents with the.\"\n",
      "  Speaker B: \"And I will make edits.\"\n",
      "Note: Simultaneous speaking; Speaker B begins responding before Speaker A completes the question.\n",
      "----\n",
      "Crosstalk 3\n",
      "Crosstalk detected from 00:06:16 to 00:06:20\n",
      "Speakers involved: Speaker B, Speaker C\n",
      "Overlapping lines:\n",
      "  Speaker B: \"If they're available.\"\n",
      "  Speaker C: \"The connection is a little rough here.\"\n",
      "Note: Speaker C comments on technical issues while Speaker B is responding, resulting in overlapping speech.\n",
      "----\n",
      "Crosstalk 4\n",
      "Crosstalk detected from 00:07:27 to 00:07:28\n",
      "Speakers involved: Speaker B, Speaker A\n",
      "Overlapping lines:\n",
      "  Speaker B: \"President.\"\n",
      "  Speaker A: \"I'm sorry. I'm sorry to cut you off.\"\n",
      "Note: Speaker A interrupts Speaker B mid-response.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for i, event in enumerate(crosstalk_response.events):\n",
    "    print(f\"Crosstalk {i+1}\")\n",
    "    pretty_print(event)\n",
    "    print(f\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a1641b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "\n",
    "# for experiment in range(0,5):\n",
    "#     crosstalk_response, raw_crosstalk_completion = client.chat.completions.create_with_completion(\n",
    "#     model=\"qwen-3\",\n",
    "#     response_model=CrossTalkEvent,\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "#         {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(raw_transcript=RAW_TRANSCRIPT)},\n",
    "#     ],\n",
    "#     temperature=0.6,\n",
    "#     )\n",
    "#     results.append(len(crosstalk_response.events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # high temperature - faster, but unstable results\n",
    "# # low temperature - slower, more stable results\n",
    "# results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0fab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vs_ds_assessment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
